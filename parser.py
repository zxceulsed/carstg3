import requests
from bs4 import BeautifulSoup
import random
import re
from db import ad_exists, add_ad

import requests
import random
import re
from bs4 import BeautifulSoup
from db import get_custom_link

def clean_text(text: str) -> str:
    return re.sub(r"\s+", " ", text.strip())

def get_random_cars(
    min_price=500,
    max_price=3000,
    count=1,
    max_photos=10,
    max_pages=20,
    base_url: str | None = None
):
    headers = {"User-Agent": "Mozilla/5.0"}

    # ÐµÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½ ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ‹Ð¹ Ð»Ð¸Ð½Ðº â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ³Ð¾
    if base_url:
        urls = [base_url]
    else:
        urls = [
            f"https://cars.av.by/filter?price_usd[min]={min_price}&price_usd[max]={max_price}&page={random.randint(1, 10)}"
            for _ in range(max_pages)
        ]

    for url in urls:
        try:
            response = requests.get(url, headers=headers, timeout=10)
        except requests.RequestException:
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        items = soup.find_all("div", class_="listing-item")
        if not items:
            continue

        random.shuffle(items)
        results = []

        for random_item in items:
            if len(results) >= count:
                break

            title_tag = random_item.find("a", class_="listing-item__link")
            link = "https://cars.av.by" + title_tag["href"] if title_tag else ""
            if not link or ad_exists(link):
                continue

            title = title_tag.text.strip() if title_tag else "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ"

            price_tag = random_item.find("div", class_="listing-item__price-secondary")
            price_text = price_tag.text.strip().replace("â‰ˆ", "").replace(" ", "") if price_tag else "â€”"

            location_tag = random_item.find("div", class_="listing-item__location")
            location_text = location_tag.text.strip() if location_tag else "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"

            params_tag = random_item.find("div", class_="listing-item__params")
            params_text = params_tag.get_text(", ", strip=True) if params_tag else ""
            params_text = re.sub(r"(,\s*){2,}", ", ", params_text).strip(", ")

            # Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð· ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð¸Ð»Ð¸ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹
            desc_tag = random_item.find("div", class_="listing-item__message")
            description = desc_tag.text.strip() if desc_tag else ""

            adv_soup = None
            try:
                adv_resp = requests.get(link, headers=headers, timeout=10)
                adv_soup = BeautifulSoup(adv_resp.text, "html.parser")
            except requests.RequestException:
                pass

            # ÐµÑÐ»Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ð³Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð½ÐµÑ‚ â€” Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¸Ð· Ð¿Ð¾Ð»Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹
            if not description and adv_soup:
                desc_full = adv_soup.select_one(".card__comment p")
                if desc_full:
                    description = desc_full.text.strip()

            if not description:
                description = "ÐÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ"

            # --- Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð°Ð²Ñ‚Ð¾ ---
            mod_block = adv_soup.find("div", class_="card__modification") if adv_soup else None
            mod_text = clean_text(mod_block.get_text(" ", strip=True)) if mod_block else "â€”"

            # --- ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾ ---
            photos = []
            if adv_soup:
                gallery = adv_soup.select(".gallery__stage .gallery__frame img")
                for img in gallery:
                    url_img = img.get("data-src") or img.get("src")
                    if url_img and not url_img.startswith("data:image"):
                        photos.append(url_img)
                    if len(photos) >= max_photos:
                        break

            # --- Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÐµÐ¹ ---
            parts = [p.strip() for p in params_text.split(",") if p.strip()]
            year = next((p for p in parts if re.match(r"\d{4}", p)), "â€”").replace("Ð³.", "").strip()
            engine = next((p for p in parts if "Ð»" in p), "â€”")
            fuel = next((p for p in parts if any(f in p.lower() for f in ["Ð±ÐµÐ½Ð·Ð¸Ð½", "Ð´Ð¸Ð·ÐµÐ»ÑŒ", "Ð³Ð°Ð·"])), "â€”")
            transmission = next((p for p in parts if any(t in p.lower() for t in ["Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐ°", "Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚"])), "â€”")
            mileage = next((p for p in parts if "ÐºÐ¼" in p), "â€”")

            formatted_message = (
                f"ðŸš— {title}  ðŸ“… {year}\n"
                f"ðŸ›£ {mileage}  |â›½ï¸ {fuel.title()}, {engine}\n"
                f"ðŸ“¦ {transmission.title()} |âš™ï¸ {mod_text}\n"
                f"ðŸ“ {location_text}\n"
                f"ðŸ’° {price_text}\n\n"
                f"{description.strip()}\n\n"
            )

            results.append({
                "title": title,
                "price": price_text,
                "location": location_text,
                "params": params_text,
                "description": description,
                "link": link,
                "photos": photos,
                "modification": mod_text,
                "message": formatted_message
            })

            add_ad(link)

        if results:
            return results

    return []

def clean_text(text: str) -> str:
    """Ð£Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹, Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ Ð·Ð°Ð¿ÑÑ‚Ñ‹Ðµ Ð¸ Ð½ÐµÑ€Ð°Ð·Ñ€Ñ‹Ð²Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹."""
    if not text:
        return ""
    text = text.replace("\xa0", " ").replace("â€‰", " ")
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"(,\s*){2,}", ", ", text)
    text = text.strip(",. \n\t")
    return text.strip()


def parse_single_car(url, max_photos=10):
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        return None

    soup = BeautifulSoup(response.text, "html.parser")

    # ðŸ· Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº â€” ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ»Ð¾Ð²Ð¾ "ÐŸÑ€Ð¾Ð´Ð°Ð¶Ð°"
    title_block = soup.find("h1")
    title = clean_text(title_block.text) if title_block else "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ"
    title = re.sub(r"(?i)^ÐŸÑ€Ð¾Ð´Ð°Ð¶Ð°\s+", "", title).strip()  # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ "ÐŸÑ€Ð¾Ð´Ð°Ð¶Ð°" Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ

    # ðŸ§© ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
    params_block = soup.find("div", class_="card__params")
    params_text = clean_text(params_block.get_text(" ", strip=True)) if params_block else ""
    parts = [p.strip() for p in re.split(r"[,\|]", params_text) if p.strip()]

    year = gearbox = engine = fuel = mileage = "â€”"
    for p in parts:
        if re.search(r"\d{4}\s*Ð³", p):
            year = clean_text(p.replace("Ð³.", "").replace("Ð³", ""))
        elif any(x in p.lower() for x in ["Ð¼ÐµÑ…Ð°Ð½Ð¸ÐºÐ°", "Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚", "Ð²Ð°Ñ€Ð¸Ð°Ñ‚Ð¾Ñ€"]):
            gearbox = clean_text(p)
        elif re.search(r"\d+[,\.]?\d*\s*Ð»", p):
            engine = clean_text(p)
        elif any(x in p.lower() for x in ["Ð±ÐµÐ½Ð·Ð¸Ð½", "Ð´Ð¸Ð·ÐµÐ»ÑŒ", "Ð³Ð°Ð·", "ÑÐ»ÐµÐºÑ‚Ñ€Ð¾"]):
            fuel = clean_text(p)
        elif "ÐºÐ¼" in p:
            mileage = clean_text(p)

    # ðŸš— ÐšÑƒÐ·Ð¾Ð² / Ð¿Ñ€Ð¸Ð²Ð¾Ð´ / Ñ†Ð²ÐµÑ‚
    desc_block = soup.find("div", class_="card__description")
    desc_text = clean_text(desc_block.get_text(", ", strip=True)) if desc_block else "â€”"

    # âš™ï¸ ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ
    mod_block = soup.find("div", class_="card__modification")
    mod_text = clean_text(mod_block.get_text(" ", strip=True)) if mod_block else "â€”"

    # ðŸ“ Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ
    loc_block = soup.find("div", class_="card__location")
    location = clean_text(loc_block.text) if loc_block else "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"

    # ðŸ’° Ð¦ÐµÐ½Ð°
    price_block = soup.find("div", class_="card__price-primary")
    price = clean_text(price_block.text) if price_block else "â€”"

    # ðŸ“ ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ â€” ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ "ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ" Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ
    comment_block = soup.find("div", class_="card__comment")
    if comment_block:
        description = clean_text(comment_block.text)
        description = re.sub(r"(?i)^ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ", "", description).strip()
    else:
        description = "ÐÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ"

    # ðŸ–¼ Ð¤Ð¾Ñ‚Ð¾
    gallery = soup.select(".gallery__stage .gallery__frame img")
    photos = []
    for img in gallery:
        src = img.get("data-src") or img.get("src")
        if src and not src.startswith("data:image"):
            photos.append(src)
        if len(photos) >= max_photos:
            break

    return {
        "title": title,
        "year": year,
        "gearbox": gearbox,
        "engine": engine,
        "fuel": fuel,
        "mileage": mileage,
        "desc_text": desc_text,
        "mod_text": mod_text,
        "price": price,
        "location": location,
        "description": description,
        "photos": photos,
        "link": url,
    }
